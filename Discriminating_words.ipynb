{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4+s1q1GX+ofDN2dDBixJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonkipnis/TwoSampleHC/blob/master/Discriminating_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade TwoSampleHC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKzoqB6TFgIX",
        "outputId": "e5b401a4-77e3-4288-d16c-c926fadd6d23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: TwoSampleHC in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from TwoSampleHC) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from TwoSampleHC) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "from TwoSampleHC import two_sample_pvals, HigherCriticism\n"
      ],
      "metadata": {
        "id": "1mVUi-TdUYzV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data"
      ],
      "metadata": {
        "id": "TBHKI3ZdQnDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = open('pride_and_prejudice.txt', 'r').read()\n",
        "text2 = open('sense_and_sensibility.txt', 'r').read()"
      ],
      "metadata": {
        "id": "S9qC1kXX3zSr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "okKdqwRQRTbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def only_adv_adj(text):\n",
        "  #Only keeps adverbs and adjectives in a the given text\n",
        "  words = nltk.word_tokenize(text)\n",
        "  tagged_words = nltk.pos_tag(words)\n",
        "  adv_adj = [word for word, tag in tagged_words if tag.startswith('J') or tag.startswith('R')]\n",
        "  return ' '.join(adv_adj)\n",
        "\n",
        "def clean_txt(text):\n",
        "  text = re.sub(r'[^a-z0-9 -]', '', text.lower()) # lower case, only letters or digits\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "mFDksbJYRW_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c887fe-adf8-42a1-846f-d0beb71fcacc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1_p = clean_txt(only_adv_adj(text1))\n",
        "text2_p = clean_txt(only_adv_adj(text2))"
      ],
      "metadata": {
        "id": "0IsN74ck4bCk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count words"
      ],
      "metadata": {
        "id": "fQN4cTU5Q1r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the two counter object word_freq1 and word_freq2 into one counter object:\n",
        "\n",
        "word_freq1 = Counter(text1_p.split())\n",
        "word_freq2 = Counter(text2_p.split())\n",
        "\n",
        "all_words = set(word_freq1.keys() | word_freq2.keys())\n",
        "\n",
        "# 2. Create Table Data\n",
        "all_word_counts = {}\n",
        "for word in all_words:\n",
        "    all_word_counts[word] = [word_freq1.get(word, 0), word_freq2.get(word, 0)]\n"
      ],
      "metadata": {
        "id": "KJ9cIei8avv5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find P-values, HC, and HC threshold:"
      ],
      "metadata": {
        "id": "sMPYA3-poHxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = np.array([all_word_counts[k][0] for k in all_word_counts])\n",
        "list2 = np.array([all_word_counts[k][1] for k in all_word_counts])\n",
        "pvals = two_sample_pvals(list1, list2)\n",
        "\n",
        "hctest = HigherCriticism(pvals)\n",
        "hc, pstar = hctest.HC()\n"
      ],
      "metadata": {
        "id": "zYhR5LTPPYag"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report words with unusually small P-values:"
      ],
      "metadata": {
        "id": "4ByesHOFn_7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,w in enumerate(all_words):\n",
        "  if pvals[i] < pstar:\n",
        "    print(w, pvals[i])\n"
      ],
      "metadata": {
        "id": "v4nLF2UMBLEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1ec769-c553-44c1-eb3d-9dcf9492b881"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "open 0.0014524093089659045\n",
            "a-year 0.0004884377594593586\n",
            "lady 0.0009365930362053781\n",
            "simple 0.0005190422619606179\n",
            "younger 0.00019519538766256866\n",
            "unfortunate 0.0005339917306836836\n",
            "only 0.001273325097093506\n",
            "old 0.00011395439713611405\n",
            "not 1.624437165939971e-05\n",
            "own 9.023374070288857e-06\n",
            "farther 5.559404473249685e-06\n",
            "more 0.0010599164473794882\n",
            "monstrous 0.0009768166012057442\n",
            "also 2.430967987067742e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5O2fE38oWZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}